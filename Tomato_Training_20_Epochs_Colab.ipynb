{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üçÖ Tomato Leaf Disease Detection - YOLOv11 Training (20 Epochs + Augmentation)\n",
    "\n",
    "This notebook trains a YOLOv11 model on PlantVillage tomato disease dataset with robust data augmentation.\n",
    "\n",
    "**Target Classes:**\n",
    "1. Tomato_Bacterial_spot\n",
    "2. Tomato_Early_blight\n",
    "3. Tomato_Late_blight\n",
    "4. Tomato_Septoria_leaf_spot\n",
    "5. Tomato_Tomato_mosaic_virus\n",
    "6. Tomato_healthy\n",
    "\n",
    "**Training Configuration:**\n",
    "- Epochs: 20\n",
    "- Image Size: 640\n",
    "- Batch Size: 16\n",
    "- Model: YOLOv11n (nano)\n",
    "\n",
    "**Data Augmentation (Real-World Robustness):**\n",
    "- Rotation: ¬±15 degrees\n",
    "- Horizontal flip: 50% probability\n",
    "- Zoom/Scale: ¬±10%\n",
    "- Brightness: ¬±20% variation\n",
    "- Random crops: Various positions\n",
    "- HSV color jitter for lighting variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q ultralytics kaggle opencv-python-headless\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from google.colab import files\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë Step 2: Setup Kaggle API Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your kaggle.json file\n",
    "print(\"üì§ Please upload your kaggle.json file\")\n",
    "print(\"   Get it from: https://www.kaggle.com/account\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Setup Kaggle credentials\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "print(\"‚úÖ Kaggle API configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 3: Download PlantVillage Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download PlantVillage dataset from Kaggle\n",
    "!kaggle datasets download -d arjuntejaswi/plant-village --unzip -p /content/plantvillage\n",
    "\n",
    "print(\"‚úÖ Dataset downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üçÖ Step 4: Filter Tomato Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target tomato classes\n",
    "TOMATO_CLASSES = [\n",
    "    'Tomato_Bacterial_spot',\n",
    "    'Tomato_Early_blight',\n",
    "    'Tomato_Late_blight',\n",
    "    'Tomato_Septoria_leaf_spot',\n",
    "    'Tomato_Tomato_mosaic_virus',  # Note: Double 'Tomato_' is correct!\n",
    "    'Tomato_healthy'\n",
    "]\n",
    "\n",
    "# Alternative class names to try if primary name not found\n",
    "ALTERNATIVE_NAMES = {\n",
    "    'Tomato_Tomato_mosaic_virus': ['Tomato_mosaic_virus', 'Tomato__Tomato_mosaic_virus', 'Tomato___Tomato_mosaic_virus']\n",
    "}\n",
    "\n",
    "# Find dataset root\n",
    "dataset_root = Path('/content/plantvillage')\n",
    "possible_roots = [\n",
    "    dataset_root / 'PlantVillage',\n",
    "    dataset_root / 'New Plant Diseases Dataset(Augmented)' / 'New Plant Diseases Dataset(Augmented)',\n",
    "    dataset_root\n",
    "]\n",
    "\n",
    "source_dir = None\n",
    "for root in possible_roots:\n",
    "    if root.exists():\n",
    "        tomato_folders = [f for f in root.iterdir() if f.is_dir() and 'Tomato' in f.name]\n",
    "        if tomato_folders:\n",
    "            source_dir = root\n",
    "            break\n",
    "\n",
    "if source_dir is None:\n",
    "    # Search recursively\n",
    "    for item in dataset_root.rglob('*'):\n",
    "        if item.is_dir() and 'Tomato' in item.name:\n",
    "            source_dir = item.parent\n",
    "            break\n",
    "\n",
    "print(f\"üìÅ Dataset found at: {source_dir}\")\n",
    "\n",
    "# Filter and copy tomato classes\n",
    "filtered_dir = Path('/content/tomato_filtered')\n",
    "filtered_dir.mkdir(exist_ok=True)\n",
    "\n",
    "stats = {}\n",
    "for class_name in TOMATO_CLASSES:\n",
    "    source_class = source_dir / class_name\n",
    "    \n",
    "    # Try main name first\n",
    "    if source_class.exists():\n",
    "        dest_class = filtered_dir / class_name\n",
    "        shutil.copytree(source_class, dest_class, dirs_exist_ok=True)\n",
    "        \n",
    "        image_count = len(list(dest_class.glob('*.jpg'))) + len(list(dest_class.glob('*.JPG')))\n",
    "        stats[class_name] = image_count\n",
    "        print(f\"‚úÖ {class_name}: {image_count} images\")\n",
    "    # Try alternative names\n",
    "    elif class_name in ALTERNATIVE_NAMES:\n",
    "        found = False\n",
    "        for alt_name in ALTERNATIVE_NAMES[class_name]:\n",
    "            alt_source = source_dir / alt_name\n",
    "            if alt_source.exists():\n",
    "                dest_class = filtered_dir / class_name\n",
    "                shutil.copytree(alt_source, dest_class, dirs_exist_ok=True)\n",
    "                \n",
    "                image_count = len(list(dest_class.glob('*.jpg'))) + len(list(dest_class.glob('*.JPG')))\n",
    "                stats[class_name] = image_count\n",
    "                print(f\"‚úÖ {class_name}: {image_count} images (found as {alt_name})\")\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            print(f\"‚ö†Ô∏è  {class_name}: Not found in dataset\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {class_name}: Not found in dataset\")\n",
    "\n",
    "# Update TOMATO_CLASSES to only include found classes\n",
    "TOMATO_CLASSES = list(stats.keys())\n",
    "print(f\"\\nüìä Total: {sum(stats.values())} images across {len(stats)} classes\")\n",
    "print(f\"\\nüìã Final classes for training: {TOMATO_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Step 5: Apply Comprehensive Manual Augmentation\n",
    "\n",
    "This step creates augmented versions of training images to expand the dataset and improve model robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import cv2\n",
    "\n",
    "def apply_augmentation(img, aug_type):\n",
    "    \"\"\"\n",
    "    Apply specific augmentation to an image.\n",
    "    \n",
    "    Augmentation types:\n",
    "    - rotate_15: Rotate ¬±15 degrees\n",
    "    - flip_h: Horizontal flip\n",
    "    - zoom_in: Zoom in 10%\n",
    "    - zoom_out: Zoom out 10%\n",
    "    - bright: Increase brightness 20%\n",
    "    - dark: Decrease brightness 20%\n",
    "    - crop_tl: Crop from top-left\n",
    "    - crop_tr: Crop from top-right\n",
    "    - crop_bl: Crop from bottom-left\n",
    "    - crop_br: Crop from bottom-right\n",
    "    - crop_center: Crop from center\n",
    "    \"\"\"\n",
    "    img_array = np.array(img)\n",
    "    h, w = img_array.shape[:2]\n",
    "    \n",
    "    if aug_type == 'rotate_15':\n",
    "        angle = random.uniform(-15, 15)\n",
    "        center = (w // 2, h // 2)\n",
    "        matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        rotated = cv2.warpAffine(img_array, matrix, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "        return Image.fromarray(rotated)\n",
    "    \n",
    "    elif aug_type == 'flip_h':\n",
    "        return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    \n",
    "    elif aug_type == 'zoom_in':\n",
    "        # Zoom in 10% (crop center and resize)\n",
    "        crop_size = int(min(w, h) * 0.9)\n",
    "        left = (w - crop_size) // 2\n",
    "        top = (h - crop_size) // 2\n",
    "        cropped = img.crop((left, top, left + crop_size, top + crop_size))\n",
    "        return cropped.resize((w, h), Image.LANCZOS)\n",
    "    \n",
    "    elif aug_type == 'zoom_out':\n",
    "        # Zoom out 10% (add padding)\n",
    "        new_size = int(min(w, h) * 1.1)\n",
    "        resized = img.resize((int(w * 0.9), int(h * 0.9)), Image.LANCZOS)\n",
    "        new_img = Image.new('RGB', (w, h), (0, 0, 0))\n",
    "        paste_x = (w - resized.width) // 2\n",
    "        paste_y = (h - resized.height) // 2\n",
    "        new_img.paste(resized, (paste_x, paste_y))\n",
    "        return new_img\n",
    "    \n",
    "    elif aug_type == 'bright':\n",
    "        enhancer = ImageEnhance.Brightness(img)\n",
    "        return enhancer.enhance(1.2)  # 20% brighter\n",
    "    \n",
    "    elif aug_type == 'dark':\n",
    "        enhancer = ImageEnhance.Brightness(img)\n",
    "        return enhancer.enhance(0.8)  # 20% darker\n",
    "    \n",
    "    elif aug_type.startswith('crop_'):\n",
    "        # Random crop from different positions (90% of image)\n",
    "        crop_size = int(min(w, h) * 0.9)\n",
    "        \n",
    "        if aug_type == 'crop_tl':  # Top-left\n",
    "            left, top = 0, 0\n",
    "        elif aug_type == 'crop_tr':  # Top-right\n",
    "            left, top = w - crop_size, 0\n",
    "        elif aug_type == 'crop_bl':  # Bottom-left\n",
    "            left, top = 0, h - crop_size\n",
    "        elif aug_type == 'crop_br':  # Bottom-right\n",
    "            left, top = w - crop_size, h - crop_size\n",
    "        else:  # crop_center\n",
    "            left = (w - crop_size) // 2\n",
    "            top = (h - crop_size) // 2\n",
    "        \n",
    "        cropped = img.crop((left, top, left + crop_size, top + crop_size))\n",
    "        return cropped.resize((w, h), Image.LANCZOS)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Create augmented dataset directory\n",
    "augmented_dir = Path('/content/tomato_augmented')\n",
    "augmented_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Define augmentation strategies\n",
    "AUGMENTATIONS = [\n",
    "    'rotate_15',\n",
    "    'flip_h',\n",
    "    'zoom_in',\n",
    "    'bright',\n",
    "    'dark',\n",
    "    'crop_center'\n",
    "]\n",
    "\n",
    "print(\"üé® Applying comprehensive augmentation...\")\n",
    "print(f\"   Augmentation types: {len(AUGMENTATIONS)}\")\n",
    "print(f\"   Expected dataset expansion: {len(AUGMENTATIONS) + 1}x\\n\")\n",
    "\n",
    "aug_stats = {}\n",
    "for class_name in TOMATO_CLASSES:\n",
    "    source_class = filtered_dir / class_name\n",
    "    dest_class = augmented_dir / class_name\n",
    "    dest_class.mkdir(exist_ok=True)\n",
    "    \n",
    "    images = list(source_class.glob('*.jpg')) + list(source_class.glob('*.JPG'))\n",
    "    original_count = len(images)\n",
    "    augmented_count = 0\n",
    "    \n",
    "    for img_path in images:\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            # Save original\n",
    "            orig_dest = dest_class / f\"{img_path.stem}_orig.jpg\"\n",
    "            img.save(orig_dest, quality=95)\n",
    "            augmented_count += 1\n",
    "            \n",
    "            # Apply each augmentation\n",
    "            for aug_type in AUGMENTATIONS:\n",
    "                aug_img = apply_augmentation(img, aug_type)\n",
    "                aug_dest = dest_class / f\"{img_path.stem}_{aug_type}.jpg\"\n",
    "                aug_img.save(aug_dest, quality=95)\n",
    "                augmented_count += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error processing {img_path.name}: {e}\")\n",
    "    \n",
    "    aug_stats[class_name] = {\n",
    "        'original': original_count,\n",
    "        'augmented': augmented_count\n",
    "    }\n",
    "    print(f\"‚úÖ {class_name}: {original_count} ‚Üí {augmented_count} images ({augmented_count/original_count:.1f}x)\")\n",
    "\n",
    "total_original = sum(s['original'] for s in aug_stats.values())\n",
    "total_augmented = sum(s['augmented'] for s in aug_stats.values())\n",
    "print(f\"\\nüìä Total: {total_original} ‚Üí {total_augmented} images ({total_augmented/total_original:.1f}x expansion)\")\n",
    "print(\"‚úÖ Comprehensive augmentation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 6: Convert Augmented Dataset to YOLO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Create YOLO directory structure\n",
    "yolo_dir = Path('/content/tomato_yolo')\n",
    "for split in ['train', 'val', 'test']:\n",
    "    (yolo_dir / split / 'images').mkdir(parents=True, exist_ok=True)\n",
    "    (yolo_dir / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Split ratios\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.2\n",
    "TEST_RATIO = 0.1\n",
    "\n",
    "# Process each class from augmented dataset\n",
    "class_mapping = {name: idx for idx, name in enumerate(TOMATO_CLASSES)}\n",
    "split_counts = {'train': 0, 'val': 0, 'test': 0}\n",
    "\n",
    "for class_name, class_id in class_mapping.items():\n",
    "    class_dir = augmented_dir / class_name\n",
    "    images = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.JPG'))\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    n_train = int(len(images) * TRAIN_RATIO)\n",
    "    n_val = int(len(images) * VAL_RATIO)\n",
    "    \n",
    "    splits = {\n",
    "        'train': images[:n_train],\n",
    "        'val': images[n_train:n_train+n_val],\n",
    "        'test': images[n_train+n_val:]\n",
    "    }\n",
    "    \n",
    "    for split_name, split_images in splits.items():\n",
    "        for img_path in split_images:\n",
    "            # Copy image\n",
    "            img_name = f\"{class_name}_{img_path.stem}{img_path.suffix}\"\n",
    "            dest_img = yolo_dir / split_name / 'images' / img_name\n",
    "            shutil.copy2(img_path, dest_img)\n",
    "            \n",
    "            # Create label (full image bounding box)\n",
    "            label_name = f\"{class_name}_{img_path.stem}.txt\"\n",
    "            label_path = yolo_dir / split_name / 'labels' / label_name\n",
    "            with open(label_path, 'w') as f:\n",
    "                f.write(f\"{class_id} 0.5 0.5 1.0 1.0\\n\")\n",
    "            \n",
    "            split_counts[split_name] += 1\n",
    "\n",
    "print(\"üìä Augmented Dataset Split:\")\n",
    "print(f\"   Train: {split_counts['train']} images\")\n",
    "print(f\"   Val: {split_counts['val']} images\")\n",
    "print(f\"   Test: {split_counts['test']} images\")\n",
    "print(f\"   Total: {sum(split_counts.values())} images\")\n",
    "print(\"‚úÖ YOLO format conversion complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Step 7: Create Dataset YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset.yaml\n",
    "dataset_yaml = {\n",
    "    'path': str(yolo_dir),\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'test': 'test/images',\n",
    "    'nc': len(TOMATO_CLASSES),\n",
    "    'names': TOMATO_CLASSES\n",
    "}\n",
    "\n",
    "yaml_path = yolo_dir / 'dataset.yaml'\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(dataset_yaml, f, default_flow_style=False)\n",
    "\n",
    "print(f\"‚úÖ Dataset YAML created at: {yaml_path}\")\n",
    "print(\"\\nüìÑ Content:\")\n",
    "print(yaml.dump(dataset_yaml, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 8: Train YOLOv11 Model (20 Epochs + Runtime Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLOv11n model\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "# Train the model with comprehensive augmentation for real-world robustness\n",
    "# Augmentation strategy:\n",
    "# - degrees=15: Rotate images ¬±15 degrees (handles different camera angles)\n",
    "# - scale=0.1: Zoom in/out by ¬±10% (handles varying distances)\n",
    "# - translate=0.15: Random crops at different positions (handles leaf positioning)\n",
    "# - fliplr=0.5: Horizontal flip 50% of time (handles leaf orientation)\n",
    "# - flipud=0.0: No vertical flip (leaves don't grow upside down)\n",
    "# - hsv_v=0.2: Brightness variation ¬±20% (handles lighting conditions)\n",
    "# - hsv_s=0.5: Saturation variation (handles color differences)\n",
    "# - hsv_h=0.01: Slight hue shift (maintains leaf color integrity)\n",
    "# - mosaic=0.0: Disabled (not suitable for full-image classification)\n",
    "# - mixup=0.0: Disabled (not suitable for full-image classification)\n",
    "\n",
    "results = model.train(\n",
    "    data=str(yaml_path),\n",
    "    epochs=20,              # Reduced to 20 epochs as requested\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=0,\n",
    "    name='tomato_disease_yolo11n_20ep',\n",
    "    augment=True,           # Enable augmentation\n",
    "    degrees=15.0,           # ¬±15¬∞ rotation for angle variations\n",
    "    scale=0.1,              # ¬±10% zoom for distance variations\n",
    "    translate=0.15,         # Random crops at different positions\n",
    "    fliplr=0.5,             # 50% horizontal flip probability\n",
    "    flipud=0.0,             # No vertical flip (unrealistic)\n",
    "    hsv_h=0.01,             # Minimal hue shift (keep leaf color natural)\n",
    "    hsv_s=0.5,              # Moderate saturation variation\n",
    "    hsv_v=0.2,              # ¬±20% brightness (darker/brighter lighting)\n",
    "    mosaic=0.0,             # Disabled - not suitable for classification\n",
    "    mixup=0.0,              # Disabled - not suitable for classification\n",
    "    copy_paste=0.0,         # Disabled - not suitable for classification\n",
    "    perspective=0.0,        # Disabled to maintain leaf shape integrity\n",
    "    shear=0.0               # Disabled to maintain leaf shape integrity\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training complete with robust augmentation!\")\n",
    "print(\"\\nüìä Augmentation Summary:\")\n",
    "print(\"   ‚úì Rotation: ¬±15¬∞ (angle robustness)\")\n",
    "print(\"   ‚úì Horizontal flip: 50% (orientation robustness)\")\n",
    "print(\"   ‚úì Zoom: ¬±10% (distance robustness)\")\n",
    "print(\"   ‚úì Brightness: ¬±20% (lighting robustness)\")\n",
    "print(\"   ‚úì Random crops: Various positions (leaf position robustness)\")\n",
    "print(\"   ‚úì Color jitter: HSV variations (real-world color robustness)\")\n",
    "print(\"\\n‚è≠Ô∏è  Next: Run Step 9 (Validate), Step 10 (Export), then Step 11 (Auto-Download)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 9: Validate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate on test set\n",
    "metrics = model.val(data=str(yaml_path), split='test')\n",
    "\n",
    "print(\"\\nüìä Validation Metrics:\")\n",
    "print(f\"   mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"   mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"   Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"   Recall: {metrics.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 10: Export Model to Multiple Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì§ Exporting model to multiple formats...\\n\")\n",
    "\n",
    "# Export to TFLite (INT8 quantized for mobile)\n",
    "print(\"1Ô∏è‚É£ Exporting to TFLite INT8 (quantized, smallest size)...\")\n",
    "model.export(format='tflite', int8=True, data=str(yaml_path))\n",
    "print(\"   ‚úÖ TFLite INT8 exported!\\n\")\n",
    "\n",
    "# Export to TFLite Float16 (good balance)\n",
    "print(\"2Ô∏è‚É£ Exporting to TFLite Float16 (balanced)...\")\n",
    "try:\n",
    "    model.export(format='tflite', half=True, data=str(yaml_path))\n",
    "    print(\"   ‚úÖ TFLite Float16 exported!\\n\")\n",
    "except:\n",
    "    print(\"   ‚ö†Ô∏è  Float16 export not available\\n\")\n",
    "\n",
    "# Export to TFLite Float32 (highest accuracy)\n",
    "print(\"3Ô∏è‚É£ Exporting to TFLite Float32 (highest accuracy)...\")\n",
    "try:\n",
    "    model.export(format='tflite', data=str(yaml_path))\n",
    "    print(\"   ‚úÖ TFLite Float32 exported!\\n\")\n",
    "except:\n",
    "    print(\"   ‚ö†Ô∏è  Float32 export not available\\n\")\n",
    "\n",
    "print(\"‚úÖ All model exports complete!\")\n",
    "print(\"\\nüìä Model Formats:\")\n",
    "print(\"   ‚Ä¢ best.pt - PyTorch model (for Python inference)\")\n",
    "print(\"   ‚Ä¢ best_int8.tflite - Quantized TFLite (smallest, for Android)\")\n",
    "print(\"   ‚Ä¢ best_float16.tflite - Half precision (balanced)\")\n",
    "print(\"   ‚Ä¢ best_float32.tflite - Full precision (highest accuracy)\")\n",
    "print(\"\\n‚è≠Ô∏è  Next: Run Step 11 to automatically download all files!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 11: Automatically Download All Trained Models & Results\n",
    "\n",
    "This cell automatically downloads all important files to your computer after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import zipfile\n",
    "\n",
    "print(\"üì¶ Preparing files for automatic download...\\n\")\n",
    "\n",
    "# Define all files to download\n",
    "run_dir = Path('/content/runs/detect/tomato_disease_yolo11n_20ep')\n",
    "weights_dir = run_dir / 'weights'\n",
    "tflite_dir = weights_dir / 'best_saved_model'\n",
    "\n",
    "files_to_download = [\n",
    "    # PyTorch models\n",
    "    (weights_dir / 'best.pt', 'best.pt', 'Best PyTorch model'),\n",
    "    (weights_dir / 'last.pt', 'last.pt', 'Last epoch PyTorch model'),\n",
    "    \n",
    "    # TFLite models\n",
    "    (tflite_dir / 'best_int8.tflite', 'best_int8.tflite', 'Quantized TFLite model (INT8)'),\n",
    "    (tflite_dir / 'best_float32.tflite', 'best_float32.tflite', 'Float32 TFLite model'),\n",
    "    (tflite_dir / 'best_float16.tflite', 'best_float16.tflite', 'Float16 TFLite model'),\n",
    "    \n",
    "    # Training results\n",
    "    (run_dir / 'results.png', 'results.png', 'Training curves'),\n",
    "    (run_dir / 'results.csv', 'results.csv', 'Training metrics CSV'),\n",
    "    (run_dir / 'confusion_matrix.png', 'confusion_matrix.png', 'Confusion matrix'),\n",
    "    (run_dir / 'confusion_matrix_normalized.png', 'confusion_matrix_normalized.png', 'Normalized confusion matrix'),\n",
    "    \n",
    "    # Additional metrics\n",
    "    (run_dir / 'F1_curve.png', 'F1_curve.png', 'F1 score curve'),\n",
    "    (run_dir / 'PR_curve.png', 'PR_curve.png', 'Precision-Recall curve'),\n",
    "    (run_dir / 'P_curve.png', 'P_curve.png', 'Precision curve'),\n",
    "    (run_dir / 'R_curve.png', 'R_curve.png', 'Recall curve'),\n",
    "]\n",
    "\n",
    "# Download each file individually\n",
    "downloaded_files = []\n",
    "for file_path, display_name, description in files_to_download:\n",
    "    if file_path.exists():\n",
    "        try:\n",
    "            files.download(str(file_path))\n",
    "            downloaded_files.append(display_name)\n",
    "            print(f\"‚úÖ Downloaded: {display_name} ({description})\")\n",
    "            time.sleep(0.5)  # Small delay between downloads\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Failed to download {display_name}: {e}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Not found: {display_name}\")\n",
    "\n",
    "# Create a comprehensive ZIP archive\n",
    "print(\"\\nüì¶ Creating comprehensive ZIP archive...\")\n",
    "zip_path = Path('/content/tomato_yolo11n_20ep_complete.zip')\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    # Add all training outputs\n",
    "    for file_path, display_name, description in files_to_download:\n",
    "        if file_path.exists():\n",
    "            zipf.write(file_path, f'tomato_yolo11n_20ep/{display_name}')\n",
    "    \n",
    "    # Add dataset YAML\n",
    "    yaml_file = yolo_dir / 'dataset.yaml'\n",
    "    if yaml_file.exists():\n",
    "        zipf.write(yaml_file, 'tomato_yolo11n_20ep/dataset.yaml')\n",
    "    \n",
    "    # Add sample predictions if available\n",
    "    predict_dir = Path('/content/runs/detect/predict')\n",
    "    if predict_dir.exists():\n",
    "        for img in list(predict_dir.glob('*.jpg'))[:5]:\n",
    "            zipf.write(img, f'tomato_yolo11n_20ep/sample_predictions/{img.name}')\n",
    "\n",
    "# Download the complete ZIP\n",
    "if zip_path.exists():\n",
    "    print(f\"\\nüì• Downloading complete archive: {zip_path.name}\")\n",
    "    files.download(str(zip_path))\n",
    "    print(f\"‚úÖ Complete! Archive size: {zip_path.stat().st_size / (1024*1024):.1f} MB\")\n",
    "\n",
    "print(f\"\\nüéâ All files downloaded successfully!\")\n",
    "print(f\"   Individual files: {len(downloaded_files)}\")\n",
    "print(f\"   Complete archive: tomato_yolo11n_20ep_complete.zip\")\n",
    "print(f\"\\nüí° Tip: The ZIP archive contains everything in one convenient package!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 12: Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a sample image\n",
    "test_images = list((yolo_dir / 'test' / 'images').glob('*.jpg'))[:5]\n",
    "\n",
    "for test_img in test_images:\n",
    "    results = model.predict(source=str(test_img), save=True, conf=0.5)\n",
    "    print(f\"‚úÖ Processed: {test_img.name}\")\n",
    "\n",
    "print(\"\\nüìÅ Results saved to: /content/runs/detect/predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ AUTOMATED: Validate, Export & Download (Run This After Training!)\n",
    "\n",
    "**This cell automatically:**\n",
    "1. Validates the model on test set\n",
    "2. Exports to all TFLite formats\n",
    "3. Downloads all files to your computer\n",
    "\n",
    "Just run this one cell after training completes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import zipfile\n",
    "from IPython.display import Image as IPImage, display\n",
    "\n",
    "print(\"üöÄ Starting automated post-training workflow...\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: VALIDATE MODEL\n",
    "# ============================================================================\n",
    "print(\"\\nüìä STEP 1: Validating model on test set...\\n\")\n",
    "metrics = model.val(data=str(yaml_path), split='test')\n",
    "\n",
    "print(\"\\n‚úÖ Validation Metrics:\")\n",
    "print(f\"   ‚Ä¢ mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"   ‚Ä¢ mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"   ‚Ä¢ Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"   ‚Ä¢ Recall: {metrics.box.mr:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: EXPORT TO MULTIPLE FORMATS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nüì§ STEP 2: Exporting model to multiple formats...\\n\")\n",
    "\n",
    "# Export to TFLite INT8\n",
    "print(\"1Ô∏è‚É£ Exporting to TFLite INT8 (quantized, smallest size)...\")\n",
    "try:\n",
    "    model.export(format='tflite', int8=True, data=str(yaml_path))\n",
    "    print(\"   ‚úÖ TFLite INT8 exported!\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è  INT8 export failed: {e}\")\n",
    "\n",
    "# Export to TFLite Float16\n",
    "print(\"\\n2Ô∏è‚É£ Exporting to TFLite Float16 (balanced)...\")\n",
    "try:\n",
    "    model.export(format='tflite', half=True, data=str(yaml_path))\n",
    "    print(\"   ‚úÖ TFLite Float16 exported!\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è  Float16 export failed: {e}\")\n",
    "\n",
    "# Export to TFLite Float32\n",
    "print(\"\\n3Ô∏è‚É£ Exporting to TFLite Float32 (highest accuracy)...\")\n",
    "try:\n",
    "    model.export(format='tflite', data=str(yaml_path))\n",
    "    print(\"   ‚úÖ TFLite Float32 exported!\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è  Float32 export failed: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: TEST INFERENCE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nüéØ STEP 3: Running test inference on sample images...\\n\")\n",
    "\n",
    "test_images = list((yolo_dir / 'test' / 'images').glob('*.jpg'))[:5]\n",
    "for test_img in test_images:\n",
    "    results = model.predict(source=str(test_img), save=True, conf=0.5)\n",
    "    print(f\"   ‚úÖ Processed: {test_img.name}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: DISPLAY RESULTS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nüìä STEP 4: Displaying training results...\\n\")\n",
    "\n",
    "# Display training curves\n",
    "results_path = Path('/content/runs/detect/tomato_disease_yolo11n_20ep/results.png')\n",
    "if results_path.exists():\n",
    "    print(\"üìà Training Curves:\")\n",
    "    display(IPImage(filename=str(results_path)))\n",
    "\n",
    "# Display confusion matrix\n",
    "confusion_matrix_path = Path('/content/runs/detect/tomato_disease_yolo11n_20ep/confusion_matrix.png')\n",
    "if confusion_matrix_path.exists():\n",
    "    print(\"\\nüìä Confusion Matrix:\")\n",
    "    display(IPImage(filename=str(confusion_matrix_path)))\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: AUTOMATIC DOWNLOAD\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nüì• STEP 5: Automatically downloading all files to your computer...\\n\")\n",
    "\n",
    "run_dir = Path('/content/runs/detect/tomato_disease_yolo11n_20ep')\n",
    "weights_dir = run_dir / 'weights'\n",
    "tflite_dir = weights_dir / 'best_saved_model'\n",
    "\n",
    "files_to_download = [\n",
    "    (weights_dir / 'best.pt', 'best.pt', 'Best PyTorch model'),\n",
    "    (weights_dir / 'last.pt', 'last.pt', 'Last epoch model'),\n",
    "    (tflite_dir / 'best_int8.tflite', 'best_int8.tflite', 'INT8 TFLite'),\n",
    "    (tflite_dir / 'best_float32.tflite', 'best_float32.tflite', 'Float32 TFLite'),\n",
    "    (tflite_dir / 'best_float16.tflite', 'best_float16.tflite', 'Float16 TFLite'),\n",
    "    (run_dir / 'results.png', 'results.png', 'Training curves'),\n",
    "    (run_dir / 'results.csv', 'results.csv', 'Metrics CSV'),\n",
    "    (run_dir / 'confusion_matrix.png', 'confusion_matrix.png', 'Confusion matrix'),\n",
    "]\n",
    "\n",
    "# Download individual files\n",
    "downloaded_count = 0\n",
    "for file_path, display_name, description in files_to_download:\n",
    "    if file_path.exists():\n",
    "        try:\n",
    "            files.download(str(file_path))\n",
    "            print(f\"   ‚úÖ {display_name} ({description})\")\n",
    "            downloaded_count += 1\n",
    "            time.sleep(0.3)\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Failed: {display_name}\")\n",
    "\n",
    "# Create and download ZIP archive\n",
    "print(\"\\nüì¶ Creating complete ZIP archive...\")\n",
    "zip_path = Path('/content/tomato_yolo11n_20ep_complete.zip')\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for file_path, display_name, description in files_to_download:\n",
    "        if file_path.exists():\n",
    "            zipf.write(file_path, f'tomato_yolo11n_20ep/{display_name}')\n",
    "    \n",
    "    # Add dataset YAML\n",
    "    yaml_file = yolo_dir / 'dataset.yaml'\n",
    "    if yaml_file.exists():\n",
    "        zipf.write(yaml_file, 'tomato_yolo11n_20ep/dataset.yaml')\n",
    "    \n",
    "    # Add sample predictions\n",
    "    predict_dir = Path('/content/runs/detect/predict')\n",
    "    if predict_dir.exists():\n",
    "        for img in list(predict_dir.glob('*.jpg'))[:5]:\n",
    "            zipf.write(img, f'tomato_yolo11n_20ep/predictions/{img.name}')\n",
    "\n",
    "if zip_path.exists():\n",
    "    files.download(str(zip_path))\n",
    "    zip_size = zip_path.stat().st_size / (1024*1024)\n",
    "    print(f\"   ‚úÖ Complete archive ({zip_size:.1f} MB)\")\n",
    "\n",
    "# ============================================================================\n",
    "# COMPLETION SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nüéâ AUTOMATED WORKFLOW COMPLETE!\\n\")\n",
    "print(\"üìä Summary:\")\n",
    "print(f\"   ‚úÖ Model validated (mAP50: {metrics.box.map50:.4f})\")\n",
    "print(f\"   ‚úÖ Exported to 3 TFLite formats\")\n",
    "print(f\"   ‚úÖ Downloaded {downloaded_count} individual files\")\n",
    "print(f\"   ‚úÖ Downloaded complete ZIP archive\")\n",
    "print(\"\\nüí° All files are now saved to your computer!\")\n",
    "print(\"   Use 'best_int8.tflite' for Android deployment.\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 13: Display Training Results (Optional - Already shown above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is optional - results are already displayed in the automated workflow above\n",
    "from IPython.display import Image as IPImage, display\n",
    "\n",
    "# Display training curves\n",
    "results_path = Path('/content/runs/detect/tomato_disease_yolo11n_20ep/results.png')\n",
    "if results_path.exists():\n",
    "    display(IPImage(filename=str(results_path)))\n",
    "\n",
    "# Display confusion matrix\n",
    "confusion_matrix_path = Path('/content/runs/detect/tomato_disease_yolo11n_20ep/confusion_matrix.png')\n",
    "if confusion_matrix_path.exists():\n",
    "    display(IPImage(filename=str(confusion_matrix_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Training Complete!\n",
    "\n",
    "Your YOLOv11 model has been trained for 20 epochs with comprehensive dual-layer data augmentation on the 6 tomato disease classes.\n",
    "\n",
    "**Comprehensive Augmentation Strategy:**\n",
    "\n",
    "*Pre-Training (Manual) Augmentation:*\n",
    "- ‚úì Rotation: ¬±15¬∞ variations\n",
    "- ‚úì Horizontal flip: Mirror images\n",
    "- ‚úì Zoom in: 10% closer view\n",
    "- ‚úì Brightness: +20% (brighter conditions)\n",
    "- ‚úì Darkness: -20% (darker conditions)\n",
    "- ‚úì Center crop: Different leaf positions\n",
    "- ‚úì Dataset expanded ~7x before training\n",
    "\n",
    "*Runtime (Training-Time) Augmentation:*\n",
    "- ‚úì Additional rotation: ¬±15¬∞ random\n",
    "- ‚úì Random horizontal flip: 50%\n",
    "- ‚úì Scale variation: ¬±10%\n",
    "- ‚úì Translation: ¬±15% random crops\n",
    "- ‚úì HSV color jitter: Brightness, saturation, hue variations\n",
    "\n",
    "**Benefits:**\n",
    "- Massive dataset expansion (7x original size)\n",
    "- Dual-layer augmentation (pre-training + runtime)\n",
    "- Significantly reduced overfitting\n",
    "- Excellent generalization to real-world conditions\n",
    "- Robust to lighting, angles, distances, and leaf positions\n",
    "\n",
    "**Files Generated:**\n",
    "- `best.pt` - Best PyTorch model\n",
    "- `best_int8.tflite` - Quantized TFLite model for mobile deployment\n",
    "- `results.png` - Training metrics visualization\n",
    "- `confusion_matrix.png` - Model performance analysis\n",
    "\n",
    "**Next Steps:**\n",
    "1. Download the models using the cells above\n",
    "2. Integrate into your Android app\n",
    "3. Test with real tomato leaf images"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
